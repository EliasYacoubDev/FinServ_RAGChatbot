# app/main.py

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from app.rag_chain import ask_question, stream_question
from app.pii_redactor import redact_text
from langsmith import traceable

app = FastAPI()

# Request body model
class Question(BaseModel):
    query: str

# POST endpoint for asking a question
@traceable(name="ask_endpoint")
@app.post("/ask")
def ask(question: Question):
    cleaned_query, redaction_count = redact_text(question.query) 
    result = ask_question(cleaned_query)
    # Get unique source URLs
    unique_sources = {
        doc.metadata.get("url")
        for doc in result["source_documents"]
        if doc.metadata.get("url")
    }
    return {
        "answer": result.get("result", "No answer found."),
        "sources": list(unique_sources),
        "redaction_count": redaction_count
    }

@traceable(name="stream_ask_endpoint")
@app.post("/stream_ask")
def stream_ask(question: Question):
    """
    Streams the response token-by-token as it's generated by the LLM.
    """
    cleaned_query, _ = redact_text(question.query)
    def event_stream():
        for token in stream_question(cleaned_query):
            yield token

    return StreamingResponse(event_stream(), media_type="text/plain")